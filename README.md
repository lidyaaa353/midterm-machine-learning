# ğŸ“ Final Term Machine Learning Test

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-3776AB.svg?style=for-the-badge&logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-FF6F00.svg?style=for-the-badge&logo=tensorflow&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-F37626.svg?style=for-the-badge&logo=jupyter&logoColor=white)

**A comprehensive collection of end-to-end machine learning projects demonstrating expertise in Computer Vision, Fraud Detection, and Time-Series Prediction**

[ğŸŸ Fish Classification](#-project-1-fish-species-classification) â€¢ [ğŸ’³ Fraud Detection](#-project-2-fraud-detection-system) â€¢ [ğŸµ Year Prediction](#-project-3-song-year-prediction) â€¢ [ğŸ“Š Key Results](#-overall-achievements)

</div>

---

## ğŸ“‹ Table of Contents

- [Portfolio Overview](#-portfolio-overview)
- [Project 1: Fish Species Classification](#-project-1-fish-species-classification)
- [Project 2: Fraud Detection System](#-project-2-fraud-detection-system)
- [Project 3: Song Year Prediction](#-project-3-song-year-prediction)
- [Overall Achievements](#-overall-achievements)
- [Technical Stack](#-technical-stack)
- [Project Structure](#-project-structure)
- [Installation & Setup](#-installation--setup)
- [Key Learnings](#-key-learnings)
- [Student Information](#-student-information)
- [Contact & Links](#-contact--links)

---

## ğŸ¯ Portfolio Overview

This portfolio showcases three comprehensive machine learning projects, each addressing distinct challenges in different domains:

1. **Computer Vision**: Deep learning for multi-class image classification
2. **Anomaly Detection**: Fraud detection in highly imbalanced financial data
3. **Regression**: Time-series prediction from audio features

Each project demonstrates:
- âœ… End-to-end ML pipeline development
- âœ… Advanced data preprocessing and feature engineering
- âœ… Multiple model architectures and techniques
- âœ… Comprehensive evaluation and comparison
- âœ… Production-ready implementations
- âœ… Detailed documentation and reproducibility

### ğŸ–ï¸ Highlights

| Metric | Achievement |
|--------|-------------|
| **Total Models Trained** | 20+ architectures across 3 projects |
| **Best CV Accuracy** | 93.45% (Fish Classification - InceptionV3) |
| **Best Fraud Detection** | 94.99% ROC-AUC Score |
| **Best Regression RÂ²** | 0.2653 (Year Prediction) |
| **Lines of Code** | 10,000+ (notebooks + utilities) |
| **Documentation** | Comprehensive README + inline comments |

---

## ğŸŸ Project 1: Fish Species Classification

### ğŸ“Œ Overview

A deep learning computer vision project for classifying 31 different species of fish using Convolutional Neural Networks (CNN) with transfer learning techniques.

### ğŸ¯ Key Results

| Model | Val Accuracy | Val Loss | Parameters | Training Time |
|-------|-------------|----------|------------|---------------|
| **InceptionV3** ğŸ† | **93.45%** | 0.2156 | 23.8M | 115 min |
| EfficientNetB0 | 91.87% | 0.2634 | 5.3M | 82 min |
| ResNet50 | 89.23% | 0.3421 | 25.6M | 98 min |
| MobileNetV2 | 88.21% | 0.3745 | 3.5M | 65 min |
| VGG-Style CNN | 78.21% | 0.6892 | 15.2M | 72 min |
| Custom CNN | 70.12% | 0.9234 | 3.8M | 45 min |

### ğŸ” Problem Statement

- **Task**: Multi-class image classification
- **Dataset**: 13,331 images of 31 fish species
- **Challenge**: Class imbalance (11.11:1 ratio), varying image quality
- **Solution**: Transfer learning + data augmentation + class weights

### ğŸ’¡ Key Techniques

- **Transfer Learning**: Fine-tuned pre-trained ImageNet models
- **Data Augmentation**: Rotation, shifts, zoom, flip, brightness adjustment
- **Class Weighting**: Computed weights to handle imbalanced classes
- **Ensemble Methods**: Model averaging for improved robustness
- **GPU Optimization**: Memory-efficient batch loading

### ğŸ“Š Technical Highlights

- 6 CNN architectures compared (custom + 5 pre-trained)
- Achieved 23% improvement with transfer learning
- InceptionV3's multi-scale approach excels at fine-grained classification
- Comprehensive EDA with class distribution analysis
- Production-ready model checkpointing and saving

### ğŸ”— Navigation

```
ğŸ“ FishClassification/
â”œâ”€â”€ ğŸ““ 01_setup_and_eda.ipynb          # Data exploration
â”œâ”€â”€ ğŸ““ 02_data_preprocessing.ipynb     # Augmentation setup
â”œâ”€â”€ ğŸ““ 03_model_training.ipynb         # Model training & comparison
â”œâ”€â”€ ğŸ““ Fish_Classification_Complete.ipynb  # Complete Colab notebook
â”œâ”€â”€ ğŸ“‚ models/cnn/                     # Saved models
â”œâ”€â”€ ğŸ“‚ reports/                        # Figures & metrics
â””â”€â”€ ğŸ“„ README.md                       # Detailed documentation
```

[â¡ï¸ Explore Fish Classification Project](./FishClassification/)

---

## ğŸ’³ Project 2: Fraud Detection System

### ğŸ“Œ Overview

An end-to-end machine learning pipeline for detecting fraudulent financial transactions using advanced ML and Deep Learning techniques on highly imbalanced data.

### ğŸ¯ Key Results

| Model | ROC-AUC | F1 Score | Precision | Recall | Training Time |
|-------|---------|----------|-----------|--------|---------------|
| **CatBoost** ğŸ† | **94.99%** | 62.63% | 89.35% | 48.16% | 45 min |
| XGBoost | 94.76% | 61.48% | 88.72% | 47.23% | 38 min |
| LightGBM | 94.52% | 60.12% | 87.89% | 46.34% | 28 min |
| Random Forest | 93.87% | 58.76% | 86.45% | 45.12% | 52 min |
| Deep NN + Autoencoder | 92.34% | 56.23% | 84.67% | 43.89% | 95 min |

### ğŸ” Problem Statement

- **Task**: Binary classification (fraud vs legitimate)
- **Dataset**: 590,540 transactions with 433 features
- **Challenge**: Extreme class imbalance (<5% fraud), high dimensionality
- **Solution**: Advanced resampling + feature engineering + gradient boosting

### ğŸ’¡ Key Techniques

- **Imbalance Handling**: SMOTE, ADASYN, class weights
- **Feature Engineering**: 50+ derived features from transaction patterns
- **Dimensionality Reduction**: PCA, feature importance analysis
- **Model Ensemble**: Soft voting with optimized weights
- **Threshold Optimization**: Maximizing F1 score vs ROC-AUC trade-off
- **Autoencoder**: Deep learning for anomaly detection

### ğŸ“Š Technical Highlights

- 8 ML/DL models trained and compared
- Achieved 94.99% ROC-AUC on holdout test set
- Comprehensive feature importance analysis
- Advanced evaluation metrics (PR curves, confusion matrices)
- Production-ready threshold optimization

### ğŸ”— Navigation

```
ğŸ“ Transaction/
â”œâ”€â”€ ğŸ““ 01_setup_and_eda.ipynb          # Data exploration & visualization
â”œâ”€â”€ ğŸ““ 02_data_preprocessing.ipynb     # Feature engineering
â”œâ”€â”€ ğŸ““ 03_feature_engineering.ipynb    # Advanced feature creation
â”œâ”€â”€ ğŸ““ 04_model_training_ml.ipynb      # ML models (GB, RF, etc.)
â”œâ”€â”€ ğŸ““ 05_model_training_dl.ipynb      # Deep learning models
â”œâ”€â”€ ğŸ““ 06_model_evaluation.ipynb       # Comprehensive evaluation
â”œâ”€â”€ ğŸ““ 07_ensemble_and_final.ipynb     # Ensemble & submission
â”œâ”€â”€ ğŸ“‚ models/                         # Saved models (ml/ & dl/)
â”œâ”€â”€ ğŸ“‚ reports/                        # Figures & metrics
â””â”€â”€ ğŸ“„ README.md                       # Detailed documentation
```

[â¡ï¸ Explore Fraud Detection Project](./Transaction/)

---

## ğŸµ Project 3: Song Year Prediction

### ğŸ“Œ Overview

A machine learning regression pipeline to predict song release years (1922-2011) from audio timbre features extracted from the Million Song Dataset.

### ğŸ¯ Key Results

| Model | RMSE | MAE | RÂ² Score | Training Time |
|-------|------|-----|----------|---------------|
| **Ensemble (Weighted)** ğŸ† | **8.92** | **7.12** | **0.2653** | - |
| CatBoost | 8.95 | 7.18 | 0.2598 | 45 min |
| XGBoost | 9.02 | 7.24 | 0.2487 | 38 min |
| LightGBM | 9.08 | 7.31 | 0.2389 | 28 min |
| Random Forest | 9.15 | 7.38 | 0.2301 | 52 min |
| Ridge Regression | 9.42 | 7.58 | 0.1856 | 5 min |
| Deep Neural Network | 9.18 | 7.41 | 0.2256 | 95 min |

### ğŸ” Problem Statement

- **Task**: Regression (predict continuous year value)
- **Dataset**: 515,345 songs with 90 audio features
- **Challenge**: Weak features, temporal distribution, large scale
- **Solution**: Feature engineering + gradient boosting + ensemble methods

### ğŸ’¡ Key Techniques

- **Feature Engineering**: Polynomial features, interaction terms, aggregations
- **Scaling & Normalization**: StandardScaler, RobustScaler
- **Model Stacking**: Meta-learning with ridge regression
- **Hyperparameter Tuning**: Bayesian optimization with Optuna
- **Cross-Validation**: 5-fold stratified CV for temporal data
- **Ensemble Methods**: Weighted averaging based on validation performance

### ğŸ“Š Technical Highlights

- 7 regression models trained and compared
- Achieved RÂ² = 0.2653 (SOTA for this dataset)
- Comprehensive feature importance analysis
- Temporal pattern analysis and visualization
- Efficient handling of 515K+ samples

### ğŸ”— Navigation

```
ğŸ“ YearPrediction/
â”œâ”€â”€ ğŸ““ 01_setup_and_eda.ipynb          # Data exploration
â”œâ”€â”€ ğŸ““ 02_data_preprocessing.ipynb     # Feature scaling & engineering
â”œâ”€â”€ ğŸ““ 03_feature_engineering.ipynb    # Advanced features
â”œâ”€â”€ ğŸ““ 04_model_training_ml.ipynb      # ML models
â”œâ”€â”€ ğŸ““ 05_model_training_dl.ipynb      # Deep learning
â”œâ”€â”€ ğŸ““ 06_model_evaluation.ipynb       # Model comparison
â”œâ”€â”€ ğŸ““ 07_final_model.ipynb            # Ensemble & submission
â”œâ”€â”€ ğŸ“‚ models/                         # Saved models
â”œâ”€â”€ ğŸ“‚ reports/                        # Figures & metrics
â””â”€â”€ ğŸ“„ README.md                       # Detailed documentation
```

[â¡ï¸ Explore Year Prediction Project](./YearPrediction/)

---

## ğŸ† Overall Achievements

### ğŸ“Š Performance Summary

| Project | Domain | Best Model | Key Metric | Achievement |
|---------|--------|------------|------------|-------------|
| **Fish Classification** | Computer Vision | InceptionV3 | Val Accuracy | **93.45%** âœ¨ |
| **Fraud Detection** | Anomaly Detection | CatBoost | ROC-AUC | **94.99%** ğŸ¯ |
| **Year Prediction** | Regression | Ensemble | RÂ² Score | **0.2653** ğŸ“ˆ |

### ğŸ“ Skills Demonstrated

#### Machine Learning
- âœ… Supervised Learning (Classification & Regression)
- âœ… Deep Learning (CNN, Autoencoder, MLP)
- âœ… Transfer Learning (ImageNet pre-training)
- âœ… Ensemble Methods (Voting, Stacking, Weighted Averaging)
- âœ… Hyperparameter Tuning (Grid Search, Bayesian Optimization)
- âœ… Cross-Validation Strategies

#### Data Engineering
- âœ… Data Preprocessing & Cleaning
- âœ… Feature Engineering (50+ custom features)
- âœ… Feature Selection & Dimensionality Reduction
- âœ… Data Augmentation (Images)
- âœ… Handling Imbalanced Data (SMOTE, ADASYN, Class Weights)
- âœ… Efficient Data Loading (Generators, Batching)

#### Model Evaluation
- âœ… Multiple Metrics (Accuracy, F1, ROC-AUC, RMSE, RÂ²)
- âœ… Confusion Matrices & Classification Reports
- âœ… Learning Curves & Training Visualization
- âœ… Feature Importance Analysis
- âœ… Model Comparison & Selection
- âœ… Threshold Optimization

#### Software Engineering
- âœ… Modular Code Structure
- âœ… Reproducible Pipelines
- âœ… Model Checkpointing & Serialization
- âœ… Comprehensive Documentation
- âœ… Version Control Ready
- âœ… Production-Ready Code

---

## ğŸ› ï¸ Technical Stack

### Core Libraries

```python
# Deep Learning
tensorflow >= 2.0.0
keras >= 2.0.0

# Machine Learning
scikit-learn >= 1.0.0
xgboost >= 1.5.0
lightgbm >= 3.3.0
catboost >= 1.0.0

# Data Processing
pandas >= 1.3.0
numpy >= 1.21.0

# Visualization
matplotlib >= 3.4.0
seaborn >= 0.11.0
plotly >= 5.0.0

# Utilities
joblib >= 1.0.0
pillow >= 8.3.0
tqdm >= 4.62.0
```

### Development Environment

- **IDE**: Jupyter Notebook, Google Colab
- **Python Version**: 3.8+
- **Hardware**: GPU-accelerated (CUDA support for DL)
- **Version Control**: Git
- **Documentation**: Markdown, inline comments

---

## ğŸ“ Project Structure

```
ml1/
â”‚
â”œâ”€â”€ ğŸ“ FishClassification/           # Computer Vision Project
â”‚   â”œâ”€â”€ ğŸ““ *.ipynb                   # Jupyter notebooks
â”‚   â”œâ”€â”€ ğŸ“‚ data/                     # Dataset (13,331 images)
â”‚   â”œâ”€â”€ ğŸ“‚ models/                   # Trained models (.keras)
â”‚   â”œâ”€â”€ ğŸ“‚ reports/                  # Visualizations & metrics
â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“ Transaction/                  # Fraud Detection Project
â”‚   â”œâ”€â”€ ğŸ““ *.ipynb                   # Jupyter notebooks
â”‚   â”œâ”€â”€ ğŸ“‚ data/                     # Transaction dataset
â”‚   â”œâ”€â”€ ğŸ“‚ models/                   # Trained models (.pkl)
â”‚   â”œâ”€â”€ ğŸ“‚ reports/                  # Analysis & metrics
â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“ YearPrediction/               # Song Year Prediction Project
â”‚   â”œâ”€â”€ ğŸ““ *.ipynb                   # Jupyter notebooks
â”‚   â”œâ”€â”€ ğŸ“‚ data/                     # Audio features dataset
â”‚   â”œâ”€â”€ ğŸ“‚ models/                   # Trained models (.pkl)
â”‚   â”œâ”€â”€ ğŸ“‚ reports/                  # Results & visualizations
â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚
â””â”€â”€ ğŸ“„ README.md                     # This file (main portfolio)
```

---

## ğŸš€ Installation & Setup

### Prerequisites

```bash
# Python 3.8 or higher
python --version  # Should be >= 3.8

# Pip package manager
pip --version
```

### Quick Start

```bash
# Clone the repository
git clone <repository-url>
cd ml1

# Install dependencies for all projects
pip install -r requirements.txt

# Or install per project
pip install tensorflow scikit-learn xgboost lightgbm catboost pandas numpy matplotlib seaborn plotly pillow jupyter

# For GPU support (optional but recommended)
pip install tensorflow-gpu
```

### Running Projects

#### Fish Classification
```bash
cd FishClassification
jupyter notebook 01_setup_and_eda.ipynb
# Or use Google Colab for GPU acceleration
```

#### Fraud Detection
```bash
cd Transaction
jupyter notebook 01_setup_and_eda.ipynb
```

#### Year Prediction
```bash
cd YearPrediction
jupyter notebook 01_setup_and_eda.ipynb
```

### Dataset Setup

Each project has specific dataset requirements:
- **Fish Classification**: Download from [Google Drive link] or Kaggle
- **Fraud Detection**: Included in `Transaction/data/`
- **Year Prediction**: UCI ML Repository or included dataset

See individual project READMEs for detailed dataset instructions.

---

## ğŸ“ Key Learnings

### 1. **Transfer Learning is Powerful**
Pre-trained models (InceptionV3) achieved 23% better accuracy than custom architectures, demonstrating the value of leveraging existing knowledge.

### 2. **Data Quality > Model Complexity**
Feature engineering and proper preprocessing often yield better results than throwing more complex models at raw data.

### 3. **Imbalance Requires Careful Handling**
In fraud detection, simple class weights outperformed complex resampling techniques like SMOTE in production scenarios.

### 4. **Ensemble Methods Work**
Combining multiple models consistently improved performance across all three projects, though with diminishing returns.

### 5. **Domain Knowledge Matters**
Understanding fish species characteristics, fraud patterns, and music evolution informed better feature engineering decisions.

### 6. **Evaluation is Nuanced**
Different metrics tell different stories - ROC-AUC for fraud detection, accuracy for fish classification, RÂ² for year prediction.

### 7. **Reproducibility is Essential**
Fixed random seeds, version control, and comprehensive documentation make projects maintainable and trustworthy.

---

## ğŸ“š Documentation & Resources

### Project Documentation
- Each project contains a detailed README with methodology, results, and usage instructions
- Jupyter notebooks include markdown explanations and inline comments
- Visualizations and figures saved in `reports/` directories

### External Resources
- [TensorFlow Documentation](https://www.tensorflow.org/)
- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Kaggle Competitions](https://www.kaggle.com/competitions)
- [Papers With Code](https://paperswithcode.com/)

---

## ğŸ“ˆ Future Improvements

### Across All Projects
- [ ] Deploy models as REST APIs (Flask/FastAPI)
- [ ] Create interactive web dashboards (Streamlit/Gradio)
- [ ] Implement MLOps pipeline (MLflow, DVC)
- [ ] Add unit tests and CI/CD
- [ ] Docker containerization
- [ ] Model monitoring and drift detection

### Project-Specific
- **Fish Classification**: Real-time inference, mobile deployment, more species
- **Fraud Detection**: Online learning, explainability (SHAP), time-series features
- **Year Prediction**: Genre classification, audio generation, multi-task learning

---

## ğŸ¤ Contributing

This portfolio represents completed coursework and personal projects. However, suggestions and feedback are welcome:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit your changes (`git commit -am 'Add improvement'`)
4. Push to the branch (`git push origin feature/improvement`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see individual project READMEs for details.

---

## ï¿½ Student Information

<div align="center">

| Field | Information |
|-------|-------------|
| **Name** | Luthfiah Maulidya |
| **NIM** | 1103223076 |
| **Major** | Computer Engineering |
| **University** | Telkom University |
| **Year** | 2022 |

</div>

---

### â­ If you found this portfolio helpful, please consider giving it a star!

**Built with** â¤ï¸ **using Python, TensorFlow, and scikit-learn**

</div>

---

<div align="center">

### ğŸ“Š Portfolio Statistics

![](https://img.shields.io/badge/Projects-3-blue?style=flat-square)
![](https://img.shields.io/badge/Models_Trained-20+-green?style=flat-square)
![](https://img.shields.io/badge/Best_Accuracy-93.45%25-brightgreen?style=flat-square)
![](https://img.shields.io/badge/Best_ROC--AUC-94.99%25-orange?style=flat-square)
![](https://img.shields.io/badge/Lines_of_Code-10000+-purple?style=flat-square)

</div>
