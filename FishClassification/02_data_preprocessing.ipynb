{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1df1758",
   "metadata": {},
   "source": [
    "# Fish Classification - Data Preprocessing & Augmentation\n",
    "\n",
    "This notebook handles:\n",
    "1. Image preprocessing (resizing, normalization)\n",
    "2. Data augmentation strategies\n",
    "3. Class imbalance handling with class weights\n",
    "4. Data generators setup for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath('.')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, 'models', 'cnn')\n",
    "FIGURES_DIR = os.path.join(BASE_DIR, 'reports', 'figures')\n",
    "\n",
    "config_path = os.path.join(MODELS_DIR, 'config.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "TRAIN_DIR = config['train_dir']\n",
    "VAL_DIR = config['val_dir']\n",
    "TEST_DIR = config['test_dir']\n",
    "NUM_CLASSES = config['num_classes']\n",
    "CLASSES = config['classes']\n",
    "IMG_SIZE = tuple(config['image_size'])\n",
    "BATCH_SIZE = config['batch_size']\n",
    "\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21577008",
   "metadata": {},
   "source": [
    "## 1. Compute Class Weights for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cde1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = config['class_counts_train']\n",
    "\n",
    "total_samples = sum(class_counts.values())\n",
    "class_weights = {}\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    weight = total_samples / (NUM_CLASSES * class_counts[class_name])\n",
    "    class_weights[idx] = weight\n",
    "\n",
    "print(\"Class Weights (for handling imbalance):\")\n",
    "print(\"=\" * 50)\n",
    "for idx, class_name in enumerate(CLASSES):\n",
    "    print(f\"{class_name}: {class_weights[idx]:.3f} (samples: {class_counts[class_name]})\")\n",
    "\n",
    "config['class_weights'] = {str(k): float(v) for k, v in class_weights.items()}\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6048c35",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6695559",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "print(\"Data Augmentation Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Training augmentations:\")\n",
    "print(\"  - Rotation: ¬±20¬∞\")\n",
    "print(\"  - Width/Height shift: ¬±20%\")\n",
    "print(\"  - Shear: 20%\")\n",
    "print(\"  - Zoom: ¬±20%\")\n",
    "print(\"  - Horizontal flip: Yes\")\n",
    "print(\"  - Brightness: [0.8, 1.2]\")\n",
    "print(\"\\nValidation/Test: Only rescaling (no augmentation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caca6523",
   "metadata": {},
   "source": [
    "## 3. Visualize Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(image_path, datagen, n_augmentations=8):\n",
    "    \"\"\"Visualize original image and its augmented versions.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize(IMG_SIZE)\n",
    "    img_array = np.array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    i = 1\n",
    "    for batch in datagen.flow(img_array, batch_size=1):\n",
    "        axes[i].imshow(batch[0])\n",
    "        axes[i].set_title(f'Augmented {i}')\n",
    "        axes[i].axis('off')\n",
    "        i += 1\n",
    "        if i >= 10:\n",
    "            break\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "sample_class = CLASSES[0]\n",
    "sample_img_name = os.listdir(os.path.join(TRAIN_DIR, sample_class))[0]\n",
    "sample_img_path = os.path.join(TRAIN_DIR, sample_class, sample_img_name)\n",
    "\n",
    "augment_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "fig = visualize_augmentations(sample_img_path, augment_datagen)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '04_augmentation_examples.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e366bb",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dcb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(generator, class_names, n_images=16):\n",
    "    \"\"\"Display a batch of images from the generator.\"\"\"\n",
    "    images, labels = next(generator)\n",
    "    \n",
    "    n_cols = 4\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(n_images, len(images))):\n",
    "        axes[i].imshow(images[i])\n",
    "        label_idx = np.argmax(labels[i])\n",
    "        axes[i].set_title(class_names[label_idx], fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(min(n_images, len(images)), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Training Batch (with augmentation)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "fig = show_batch(train_generator, class_names)\n",
    "plt.savefig(os.path.join(FIGURES_DIR, '05_sample_batch.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97008b2b",
   "metadata": {},
   "source": [
    "## 5. Create Transfer Learning Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generators_for_model(model_name, train_dir, val_dir, test_dir, img_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create data generators with model-specific preprocessing.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.applications import resnet50, efficientnet, mobilenet_v2, inception_v3, vgg16\n",
    "    \n",
    "    preprocessing_functions = {\n",
    "        'resnet50': resnet50.preprocess_input,\n",
    "        'efficientnet': efficientnet.preprocess_input,\n",
    "        'mobilenet': mobilenet_v2.preprocess_input,\n",
    "        'inception': inception_v3.preprocess_input,\n",
    "        'vgg16': vgg16.preprocess_input,\n",
    "        'custom': None\n",
    "    }\n",
    "    \n",
    "    preprocess_fn = preprocessing_functions.get(model_name.lower())\n",
    "    \n",
    "    if preprocess_fn:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_fn,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            brightness_range=[0.8, 1.2]\n",
    "        )\n",
    "        val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        train_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', shuffle=True, seed=42\n",
    "    )\n",
    "    \n",
    "    val_gen = val_test_datagen.flow_from_directory(\n",
    "        val_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_gen = val_test_datagen.flow_from_directory(\n",
    "        test_dir, target_size=img_size, batch_size=batch_size,\n",
    "        class_mode='categorical', shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "print(\"Generator factory function created!\")\n",
    "print(\"Supported models: ResNet50, EfficientNet, MobileNet, Inception, VGG16, Custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51297484",
   "metadata": {},
   "source": [
    "## 6. Save Preprocessing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_config = {\n",
    "    'image_size': list(IMG_SIZE),\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'augmentation': {\n",
    "        'rotation_range': 20,\n",
    "        'width_shift_range': 0.2,\n",
    "        'height_shift_range': 0.2,\n",
    "        'shear_range': 0.2,\n",
    "        'zoom_range': 0.2,\n",
    "        'horizontal_flip': True,\n",
    "        'brightness_range': [0.8, 1.2]\n",
    "    },\n",
    "    'class_weights': {str(k): float(v) for k, v in class_weights.items()},\n",
    "    'class_indices': train_generator.class_indices\n",
    "}\n",
    "\n",
    "preprocess_config_path = os.path.join(MODELS_DIR, 'preprocessing_config.json')\n",
    "with open(preprocess_config_path, 'w') as f:\n",
    "    json.dump(preprocessing_config, f, indent=2)\n",
    "\n",
    "print(f\"Preprocessing configuration saved to: {preprocess_config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db39221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìê Image Configuration:\")\n",
    "print(f\"   - Target size: {IMG_SIZE[0]}x{IMG_SIZE[1]}\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\nüîÑ Data Augmentation:\")\n",
    "print(f\"   - Rotation, shifts, shear, zoom, flip\")\n",
    "print(f\"   - Brightness adjustment\")\n",
    "print(f\"\\n‚öñÔ∏è Class Imbalance Handling:\")\n",
    "print(f\"   - Class weights computed\")\n",
    "print(f\"   - Min weight: {min(class_weights.values()):.3f}\")\n",
    "print(f\"   - Max weight: {max(class_weights.values()):.3f}\")\n",
    "print(f\"\\nüì¶ Data Generators:\")\n",
    "print(f\"   - Training: {train_generator.samples} samples\")\n",
    "print(f\"   - Validation: {val_generator.samples} samples\")\n",
    "print(f\"   - Test: {test_generator.samples} samples\")\n",
    "print(f\"\\n‚úÖ Ready for model training!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
